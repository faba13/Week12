{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c399f7-df16-43b9-ac7f-f247510bc00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coloumn and rows: (111, 31)\n",
      "3441\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# implementing diffrent Models on tha data\n",
    "#Each cell include a new method\n",
    "\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr  6 14:15:45 2021\n",
    "\n",
    "@author: bf101616\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "# import xgboost as xgb\n",
    "# from xgboost.sklearn import XGBClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "#import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from sklearn.cross_validation import train_test_split \n",
    "import numpy as np \n",
    "\n",
    "#train_data = pd.read_csv(\"train.csv\")\n",
    "#test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "#\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#import Tkinter as tk\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import numpy as np \n",
    "#import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection  import train_test_split  #mohemen in shekli bashe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "#data=pd.read_csv(\"prebp40.csv\",delimiter=\";\" ,decimal=\".\"),sep='\\t'\n",
    "data=pd.read_csv(\"Data2.csv\"  )\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#\n",
    "#S\t1\n",
    "#Es\t0\n",
    "#S\t1\n",
    "#I\t0\n",
    "#A\t1\n",
    "#N\t0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "data['sexo']=data['sexo'].replace('H',0)\n",
    "data['sexo']=data['sexo'].replace('V',1)\n",
    "\n",
    "\n",
    "data['canal_entrada']=data['canal_entrada'].replace('KHL',0)\n",
    "\n",
    "\n",
    "data['canal_entrada']=data['canal_entrada'].replace('KHE',1)\n",
    "data['canal_entrada']=data['canal_entrada'].replace('KHD',2)\n",
    "data['canal_entrada']=data['canal_entrada'].replace('KFC',3)\n",
    "data['canal_entrada']=data['canal_entrada'].replace('KAT',4)\n",
    "\n",
    "\n",
    "data['indfall']=data['indfall'].replace('N',0)\n",
    "\n",
    "data['nomprov']=data['nomprov'].replace('MALAGA',0)\n",
    "data['nomprov']=data['nomprov'].replace('MALAGA',0)\n",
    "\n",
    "\n",
    "\n",
    "#data['Weekly_othersporttrainingtime']=data['Weekly_othersporttrainingtime'].replace('Di11icile',\t2)\n",
    "#data['Weekly_othersportrainingintensity']=data['Weekly_othersportrainingintensity'].replace('Di11icile',\t2)\n",
    "#data['Weekly_competitionintensity']=data['Weekly_competitionintensity'].replace('Di11icile',\t2)\n",
    "#\tWeekly_othersporttrainingtime\tWeekly_othersportrainingintensity\n",
    "\n",
    "\n",
    "\n",
    "print('coloumn and rows:', data.shape)\n",
    "print(data.size)\n",
    "\n",
    "\n",
    "X=data.loc[2:31]\n",
    "Y=data.loc[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3899b884-54a0-4ad5-bbd1-6eb2b04b6223",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [30, 31]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Splitting the dataset into train and test \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m      7\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m      8\u001b[0m X_train \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2172\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2172\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2174\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2175\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[1;32m   2176\u001b[0m                                           default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:356\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    List of objects to ensure sliceability.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 356\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:319\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    317\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths])\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [30, 31]"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size = 0.3, random_state = 100) \n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "state = 12  \n",
    "test_size = 0.30  \n",
    "  \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,  \n",
    "    test_size=test_size, random_state=state)\n",
    "\n",
    "\n",
    "#Import libraries\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Function to split the dataset \n",
    "def splitdataset(X,Y): \n",
    "  \n",
    "    # Separating the target variable \n",
    "    #X = balance_data.values[:, 1:5] \n",
    "    #X=X75\n",
    "    #Y = balance_data.values[:, 0]\n",
    "    #Y=Y75 \n",
    "  \n",
    "    # Splitting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split( \n",
    "    X,Y,test_size = 0.3, random_state = 100) \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    state = 12  \n",
    "    test_size = 0.30  \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,  \n",
    "    test_size=test_size, random_state=state)\n",
    "\n",
    "      \n",
    "    return  X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87125d40-0be3-490d-a20f-d659a6739dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fa953f-80ad-4d70-b31b-4ba97512ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian optimization\n",
    "def bayesian_optimization(X_train, y_train, X_val, y_val, function, parameters):\n",
    "   #X_train, y_train, X_test, y_test = dataset\n",
    "  # X_train, y_train, X_test, y_test = dataset\n",
    "   n_iterations = 5\n",
    "   gp_params = {\"alpha\": 1e-4}\n",
    "\n",
    "   BO = BayesianOptimization(function, parameters)\n",
    "   BO.maximize(n_iter=n_iterations, **gp_params)\n",
    "\n",
    "   return BO.max\n",
    "\n",
    "def rfc_optimization(cv_splits):\n",
    "    def function(n_estimators, max_depth, min_samples_split):\n",
    "        return cross_val_score(\n",
    "               RandomForestClassifier(\n",
    "                   n_estimators=int(max(n_estimators,0)),                                                               \n",
    "                   max_depth=int(max(max_depth,1)),\n",
    "                   min_samples_split=int(max(min_samples_split,2)), \n",
    "                   n_jobs=-1, \n",
    "                   random_state=42,   \n",
    "                   class_weight=\"balanced\"),  \n",
    "               X=X_train, \n",
    "               y=y_train, \n",
    "               cv=cv_splits,\n",
    "               scoring=\"roc_auc\",\n",
    "               n_jobs=-1).mean()\n",
    "\n",
    "    parameters = {\"n_estimators\": (10, 1000),\n",
    "                  \"max_depth\": (1, 150),\n",
    "                  \"min_samples_split\": (2, 10)}\n",
    "    \n",
    "    return function, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb539e41-c50a-49fc-b7c6-ee4e25091118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "def train(X_train, y_train, X_test, y_test, function, parameters):\n",
    "    dataset = (X_train, y_train, X_val, y_val)\n",
    "    cv_splits = 4\n",
    "    \n",
    "    best_solution = bayesian_optimization(X_train, y_train, X_val, y_val, function, parameters)      \n",
    "    params = best_solution[\"params\"]\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "             n_estimators=int(max(params[\"n_estimators\"], 0)),\n",
    "             max_depth=int(max(params[\"max_depth\"], 1)),\n",
    "             min_samples_split=int(max(params[\"min_samples_split\"], 2)), \n",
    "             n_jobs=-1, \n",
    "             random_state=42,   \n",
    "             class_weight=\"balanced\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b22a62e-8a55-424c-96bc-08e3755fde76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_optimization(cv_splits, eval_set):\n",
    "    def function(eta, gamma, max_depth):\n",
    "            return cross_val_score(\n",
    "                   xgb.XGBClassifier(\n",
    "                       objective=\"binary:logistic\",\n",
    "                       learning_rate=max(eta, 0),\n",
    "                       gamma=max(gamma, 0),\n",
    "                       max_depth=int(max_depth),                                               \n",
    "                       seed=42,\n",
    "                       nthread=-1,\n",
    "                       scale_pos_weight = len(y_train[y_train == 0])/\n",
    "                                          len(y_train[y_train == 1])),  \n",
    "                   X=X_train, \n",
    "                   y=y_train, \n",
    "                   cv=cv_splits,\n",
    "                   scoring=\"roc_auc\",\n",
    "                   fit_params={\n",
    "                        \"early_stopping_rounds\": 10, \n",
    "                        \"eval_metric\": \"auc\", \n",
    "                        \"eval_set\": eval_set},\n",
    "                   n_jobs=-1).mean()\n",
    "\n",
    "    parameters = {\"eta\": (0.001, 0.4),\n",
    "                  \"gamma\": (0, 20),\n",
    "                  \"max_depth\": (1, 2000)}\n",
    "    \n",
    "    return function, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b842046e-37c8-4971-a1e4-7e291598f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_optimization(cv_splits, eval_set):\n",
    "    def function(eta, gamma, max_depth):\n",
    "            return cross_val_score(\n",
    "                   xgb.XGBClassifier(\n",
    "                       objective=\"binary:logistic\",\n",
    "                       learning_rate=max(eta, 0),\n",
    "                       gamma=max(gamma, 0),\n",
    "                       max_depth=int(max_depth),                                               \n",
    "                       seed=42,\n",
    "                       nthread=-1,\n",
    "                       scale_pos_weight = len(y_train[y_train == 0])/\n",
    "                                          len(y_train[y_train == 1])),  \n",
    "                   X=X_train, \n",
    "                   y=y_train, \n",
    "                   cv=cv_splits,\n",
    "                   scoring=\"roc_auc\",\n",
    "                   fit_params={\n",
    "                        \"early_stopping_rounds\": 10, \n",
    "                        \"eval_metric\": \"auc\", \n",
    "                        \"eval_set\": eval_set},\n",
    "                   n_jobs=-1).mean()\n",
    "\n",
    "    parameters = {\"eta\": (0.001, 0.4),\n",
    "                  \"gamma\": (0, 20),\n",
    "                  \"max_depth\": (1, 2000)}\n",
    "    \n",
    "    return function, parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(): \n",
    "      \n",
    "    # Building Phase \n",
    "    X_train, X_test, y_train, y_test=splitdataset(X,Y)\n",
    "    cv_splits = 4\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)]\n",
    "\n",
    "    function, parameters=rfc_optimization(cv_splits)\n",
    "    function2, parameters2=xgb_optimization(cv_splits,eval_set)\n",
    "    #Bo=bayesian_optimization(X_train, y_train, X_val, y_val, function, parameters)\n",
    "    model=train(X_train, y_train, X_test, y_test, function, parameters)\n",
    "    #model2=train(X_train, y_train, X_test, y_test, function2, parameters2)\n",
    "\n",
    "    \n",
    "\n",
    "    #pprint(model.best_estimator_.get_params())\n",
    "#print(model.best_score)\n",
    "    lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "    for learning_rate in lr_list:\n",
    "\n",
    "\n",
    "\n",
    "        print(\"Learning rate: \", learning_rate)\n",
    "        print(\"Accuracy score (training): {0:.3f}\".format(model.score(X_train, y_train)))\n",
    "        print(\"Accuracy score (validation): {0:.3f}\".format(model.score(X_val, y_val)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    predictions = model.predict(X_val)\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, predictions))\n",
    "\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_val, predictions))\n",
    "\n",
    "  #   probs = model.predict_proba(X_val)\n",
    "  #   probs = probs[:, 1]\n",
    "  #   fpr, tpr, thresholds = roc_curve(y_val, probs)\n",
    "  #  # plot_roc_curve(fpr, tpr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    xgb_clf = XGBClassifier()\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "    score = xgb_clf.score(X_val, y_val)\n",
    "    print(score)\n",
    "\n",
    "    for learning_rate in lr_list:\n",
    "\n",
    "\n",
    "\n",
    "        print(\"Learning rate: \", learning_rate)\n",
    "        print(\"Accuracy score (training): {0:.3f}\".format(xgb_clf.score(X_train, y_train)))\n",
    "        print(\"Accuracy score (validation): {0:.3f}\".format(xgb_clf.score(X_val, y_val)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    predictions2 = xgb_clf.predict(X_val)\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, predictions2))\n",
    "\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_val, predictions2))\n",
    "\n",
    "\n",
    "\n",
    "    probs = xgb_clf.predict_proba(X_val)\n",
    "    probs = probs[:, 1]\n",
    "    #fpr, tpr, thresholds = roc_curve(y_val, probs)\n",
    "   # plot_roc_curve(fpr, tpr)\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
